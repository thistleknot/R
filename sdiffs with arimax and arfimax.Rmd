```{r}
#packages
{
packages <- c("dplyr","ggplot2","quantmod","zoo","plyr","forecast","tseries","tidyverse","furrr","reticulate","geometry","reshape","lubridate","anytime","car","caret","ppcor","whitening","TSA","corrplot")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
}
```

```{r}
#data
raw <- read.csv("https://raw.githubusercontent.com/thistleknot/Python-Stock/master/data/combined_set.csv",row.names=1,header=TRUE)
```

```{r}
#functions
`%notin%` <- Negate(`%in%`)

PCOR <- function(x, type = c("raw", "cor")) {		 
		  type <- match.arg(type)
		  if (type == "raw") {		
			x <- scale(x)
			R <- (t(x) %*% x) / (nrow(x) - 1)
		  } else  {
			R <- x
		  }
		  
		  ind <- unique(dim(R))
		  R_inv <- ginv(R)
		  ZM <- matrix(rep(0, len = (ind*ind)), nrow = ind)
		  diag(ZM) <- diag(R_inv)
		  D <- ginv(ZM)
		  AICOV <- D %*% R_inv %*% D
		  diag(ZM) <- diag(AICOV)
		  D  <- ginv(sqrt(ZM))
		  AICOR <- D %*% AICOV %*% D
		  pcor <- AICOR
		  pcor[upper.tri(pcor)] <- -pcor[upper.tri(pcor)]
		  pcor[lower.tri(pcor)] <- -pcor[lower.tri(pcor)]
		  dimnames(pcor) <- list(colnames(R), colnames(R))
		  return(pcor)
		}  

critical.r <- function( n, alpha = .05 ) {
  df <- n - 2
  critical.t <- qt(alpha/2, df, lower.tail = F)
  critical.r <- sqrt( (critical.t^2) / ( (critical.t^2) + df ) )
  return(critical.r)
}

nv_diff_sets <- function(var_of_int,dataset,f_casts)
{
  #dataset=newDF_t
  #f_casts = c()
  #initialV <- dataset[1,]
  s_=sndif_[which(colnames(raw)==var_of_int)]
  d_=ndif_[which(colnames(raw)==var_of_int)]
  #-1?, based on d_?
  
  startRow = which(rownames(raw)==rownames(dataset[1:d_,,drop=FALSE]))
  
  data_ <- c(na.omit(c(dataset[,var_of_int], f_casts)))
  
  if(s_==0)
  {
    inv_d <- diffinv(data_,differences=d_,xi=raw[startRow,var_of_int])
  }else
  {
      
    inv_d <- diffinv(diffinv(data_,differences = d_, xi=raw[startRow,var_of_int]), differences = s_,xi=raw[startRow:(startRow+season-1),var_of_int])
  }
  
  return(inv_d)
  
}
```

```{python}
import numpy as np
import pandas as pd
from sklearn.utils import as_float_array
from sklearn.base import TransformerMixin, BaseEstimator

class ZCA(BaseEstimator, TransformerMixin):
  def __init__(self, regularization=1e-5, copy=False):
      self.regularization = regularization
      self.copy = copy
  def fit(self, X, y=None):
      X = as_float_array(X, copy=self.copy)
      self.mean_ = np.mean(X, axis=0)
      X = X - self.mean_
      sigma = np.dot(X.T, X) / (X.shape[0] - 1)
      U, S, V = np.linalg.svd(sigma)
      tmp = np.dot(U, np.diag(1 / np.sqrt(S + self.regularization)))
      self.components_ = np.dot(tmp, U.T)
      return self
  def transform(self, X):
      X_transformed = X - self.mean_
      X_transformed = np.dot(X_transformed, self.components_.T)
      return X_transformed  
    
```

```{r}
#vars
f = periodicity(as.Date(anytime(rownames(raw))))

options("scipen"=100, "digits"=4)

season = switch(  
  f$scale,  
  "monthly"= 12,  
  "daily"= 252,  
  "quarterly"= 4,  
  "weekly"= 52,
)  

#plot(raw$GDPC1)
#var_of_int <- "MSPUS"
#sort(colnames(raw))
#var_of_int <- "GDPC1"
var_of_int <- "LXXRCSA"
```

```{r}
#test python functions
if(FALSE)
{
  x <- read.csv(file="https://raw.githubusercontent.com/thistleknot/Python-Stock/master/data/raw/states.csv", header = TRUE, row.names = 1)
  x_ <- x[,2:ncol(x)]
  
  zca <- py$ZCA()
  
  zca$fit_transform(x_)
  
  py$zca1(as.matrix(x[,2:ncol(x)]))
}
```

```{r}
#differencing

sndif_ <- unlist(lapply(1:(length(colnames(raw))),function(n)
  {
    d_ <- nsdiffs(ts(raw[,n],frequency=season))
    return(d_)
  }))

combo_s <- do.call(cbind,lapply(1:length(sndif_), function(d)
  {
    if(sndif_[d]*season == 0)
    {
      temp <- raw[,d,drop=FALSE]
    }else
    {
      temp <- raw[,d,drop=FALSE]
      for(dif in 1:sndif_[d])
      {
        temp <- temp-dplyr::lag(temp,1*season)
      }
    }
  return(temp)
  }))

ndif_ <- c()

ndif_ <- unlist(lapply(1:(length(colnames(combo_s))),function(n)
{
  d_ <- ndiffs(combo_s[,n])
  #min 1 to ensure I'm being consistent (i.e. measuring rate of change between quarters). Note: ndiffs == na's return 0 so I handle na's in combo_d
  if(d_ == 0){d_ = 1}
  return(d_)
}))

combo_d <- do.call(cbind,lapply(1:length(ndif_),function(d)
{#no if check for 0 because at a minimum I want one difference
  s=sndif_[d]
  d_=ndif_[d]
  
  if(s>0)
  {
    
    diffset <- diff(diff(raw[,colnames(raw)[d],drop=TRUE],lag=season,differences=s),differences=d_)
  }else
  {
    diffset <- diff(raw[,colnames(raw)[d],drop=TRUE],differences=d_)
  }
  
  properSet <- as.data.frame(c(matrix(NA,nrow=(nrow(raw)-length(diffset))),diffset))
  colnames(properSet) <- colnames(raw[,colnames(raw)[d],drop=FALSE])
  rownames(properSet) <- rownames(raw)
  #View(properSet)  
  return(properSet)
}))


which(((ndif_==2)*(sndif_==1))==1)

colnames(raw)[which(((ndif_==2)*(sndif_==0))==1)[1]]
colnames(raw)[which(((ndif_==1)*(sndif_==1))==1)[1]]
colnames(raw)[which(((ndif_==1)*(sndif_==0))==1)[1]]

colnames(raw$MSPUS)

#multiplicative (returns) to log

if(FALSE)
#CFNAIDIFF has negative initial values which make calculating returns impossible
{

  combo_s_m <- do.call(cbind,lapply(1:length(sndif_),function(d)
    {
      if(sndif_[d]*season == 0)
      {
        temp <- raw[,d,drop=FALSE]
      }else
      {
        temp <- raw[,d,drop=FALSE]
        for (sdif in 1:sndif_[d])
        {

          temp <- (1+((temp-dplyr::lag(temp,1*season))/dplyr::lag(temp,1*season)))
        }
      }
    return(temp)
    }))
  
  combo_d_m <- do.call(cbind,lapply(1:length(ndif_),function(d)
  {
    #d=1
      temp <- combo_s_m[,d,drop=FALSE]
      for (dif in 1:ndif_[d])
      {
        temp <- (1+((temp-dplyr::lag(temp,1))/dplyr::lag(temp,1)))
        
        temp <- as.data.frame(lapply(temp,function(x){ifelse(is.nan(x),return(0),return(x))}))
        rownames(temp) <- rownames(combo_s_m[,d,drop=FALSE])
      }
      return(temp)
  }))

}


```

```{r}
#optimal lagged correlation
# Example usage: Critical correlation coefficient at sample size of n = 100

names <- c()
lags_ <- c()
'
numZero <- colSums(combo_d == 0, na.rm = T)

numNaN <- sapply(combo_d_m, function(x) sum(is.nan(x)))

names(which(numNaN>0))

ndif_[which(colnames(raw)=="INTDSRUSM193N")]
sndif_[which(colnames(raw)=="INTDSRUSM193N")]

limit = (nrow(raw)/2)
drops = names(which(numZero>=limit))

#lapply(combo_d, function(x){ length(which(x==0))/length(x)})

combo_ <- na.omit(dplyr::select(combo_d, -c(drops)))
'

combo_ <- combo_d
{
  training <- combo_[1:floor(nrow(combo_)*.7),]
  #validation <- training-round(nrow(combo_)*.7*.3,0)
  holdout <- combo_[(nrow(training)+1):nrow(combo_),]
}

training_nona <- na.omit(training)
  
for(c in 1:(length(colnames(training_nona))))
{#c=3
  
  temp <- na.omit(training)
  
  ccf1 <- ccf(training_nona[,var_of_int,drop=FALSE],training_nona[,c], lag.max = season, correlation=TRUE, plot=FALSE)
  
  crit = critical.r(ccf1$n.used)
  
  #upperCI <- qnorm((1+0.95)/2)/sqrt(ccf1$n.used)
  #lowerCI <- -qnorm((1+0.95)/2)/sqrt(ccf1$n.used)
  
  #ind.max <- which(abs(ccf1$acf)==max(abs(ccf1$acf)))
  candidates <- which((abs(ccf1$acf)<=crit) & (ccf1$lag >= 1))
  if(length(candidates)!=0)
  {
    which_max <- which.max(abs(ccf1$acf[candidates]))
    ind.max <- max(abs(ccf1$acf[candidates][which_max]))
    max.cor <- ccf1$acf[candidates][which_max]
    lag.opt <- ccf1$lag[candidates][which_max]
    names <- c(names,(colnames(training_nona)[c]))
    #print(colnames(training_nona)[c])
    #print(lag.opt)
    #print(max.cor)
    lags_ <- c(lags_,lag.opt)
    #print(2 * (1 - pnorm(abs(max.cor), mean = 0, sd = 1/sqrt(ccf1$n.used))))
  }
  
}

#needed if lag.opt>=0
'
if(min(lags_)==0)
{
  
}
'
#remove y (for now until I figure out how to handle the name change)
names <- names[names %notin% var_of_int]

#lag example
#cor(na.omit(cbind(training[,var_of_int,],dplyr::lag(training[,"SHY"],2))))

```

```{r}
#ZCA backstep filter

newDF_t <- training[,var_of_int,drop=FALSE]

#nrow(newDF_t)

#newDF_t <- lapply(1:length(names), function(n)
for (n in 1:length(names))
{
  #n=1
  #print(n)
  #temp=dplyr::lag(combo_[,names[n],drop=FALSE],n=abs(lags_[n]),default = NA)
  ts_ <- stats::lag(x=ts(training[,names[n],drop=FALSE],frequency=season),k=lags_[n])
  temp <- as.data.frame(matrix(ts_))

  rownames(temp) <- anydate(rownames(training)[1]) %m+% months(matrix(time(ts_))*12)
  colnames(temp) <- names[n]

  #rownames(temp)<-rownames(raw)
  #tail(raw[,var_of_int,drop=FALSE])
  #tail(raw[,"ASPUS",drop=FALSE])
  #return(temp)
  newDF_t <- cbind(newDF_t,temp)
  
}

#tail(temp)

#tail(newDF_t[,var_of_int])

#cor(na.omit(newDF_t[,c("MSPUS","M1"),]))

sig_table = matrix(0, ncol=ncol(newDF_t))
colnames(sig_table) <- colnames(newDF_t)
signs_table = matrix(0, ncol=ncol(newDF_t))
colnames(signs_table) <- colnames(newDF_t)

p_threshold = .05

#New_Names = colnames(newDF_t)[2:length(colnames(newDF_t))]
iteration=0

dat <- 1:10
n=length(dat)

#folds<-createTimeSlices(y=rownames(newDF_t),initialWindow = 20,horizon = 10)

#lapply(folds,length)

exclude <- c()

#crit <- critical.r(nrow(set_), .05)

max_pvalue = 1

subset = na.omit(newDF_t[,c(colnames(newDF_t) %notin% c(exclude))])

#View(subset[,c(colnames(newDF_t) %notin% c(var_of_int))])

#doesn't like 36+
#whitening::whiten(as.matrix(subset[,c(colnames(newDF_t) %notin% c(var_of_int))]),center=TRUE,method=c("ZCA"))

#whitening::whiteningMatrix(as.matrix(cov(subset[,c(colnames(newDF_t) %notin% c(var_of_int))])), method=c("ZCA"))

#View(sort((t(summary(subset))[,4])))

#subset_w <- cbind(subset[,var_of_int,drop=FALSE],as.data.frame(whiten(as.matrix(subset[,c(colnames(newDF_t) %notin% c(var_of_int))]),center=TRUE, method=c("ZCA"))))

zca <- py$ZCA()

#zca$fit_transform(x)
#corrplot(cor(zca$transform(x)))

subset_w <- cbind(subset[,var_of_int,drop=FALSE],as.data.frame(zca$fit_transform(as.matrix(subset[,c(colnames(newDF_t) %notin% c(var_of_int))]))))

colnames(subset_w) <- colnames(subset)
rownames(subset_w) <- rownames(subset)

#corrplot(cor(subset_w))

#set_ = subset_w[,c(colnames(newDF_t) %notin% c(var_of_int))]
#set_ = subset[,c(colnames(newDF_t) %notin% c(var_of_int))]

while(max_pvalue>=p_threshold)
{
  p_values  <- (2 * (1 - pnorm(abs(cor(subset_w)[,var_of_int,drop=FALSE]), mean = 0, sd = 1/sqrt(nrow(subset_w)))))
  #p_values  <- (2 * (1 - pnorm(abs(PCOR(subset)[,var_of_int,drop=FALSE]), mean = 0, sd = 1/sqrt(nrow(subset)))))
  
  #print(grep(var_of_int,rownames(p_values)))
  
  #pcor(subset, method = c("spearman"))$p.value[,var_of_int,drop=FALSE]
  
  max_pname = rownames(p_values)[which.max(p_values)]
  max_pvalue = p_values[max_pname,]
  
  if (max_pvalue >= p_threshold)
  {
    #print(max_pvalue)
    #print(max_pname)
    temp <- dplyr::select(subset_w,-c(max_pname))
    #temp <- dplyr::select(subset,-c(max_pname))
    if(ncol(temp)==1)
    {
      break
    }
    else
    {
      zca <- py$ZCA()
      temp_ <- cbind(subset_w[,var_of_int,drop=FALSE],as.data.frame(zca$fit_transform(as.matrix(temp[,c(colnames(temp) %notin% c(var_of_int))]))))
      #temp_ <- cbind(subset_w[,var_of_int,drop=FALSE],as.data.frame(py$white(as.matrix(temp[,c(colnames(temp) %notin% c(var_of_int))]))))
      #temp_ <- cbind(subset[,var_of_int,drop=FALSE],temp[,c(colnames(temp) %notin% c(var_of_int))])
      
  colnames(temp_) <- colnames(temp)
  rownames(temp_) <- rownames(temp)
  subset_w <- temp_
  #subset <- temp_
    }
  }
}
  
winners = rownames(p_values)[rownames(p_values) %notin% c(var_of_int)]
sig_table = sig_table + as.integer(colnames(newDF_t) %in% winners)

#t_ <- t(pcor(subset[,c(var_of_int,winners)], method = c("spearman"))$estimate[,var_of_int,drop=FALSE])[,-1]

corrplot(cor(subset_w[,c(var_of_int,winners)]))

#corrplot(PCOR(subset[,c(var_of_int,winners),drop=FALSE]))
#corrplot(PCOR(subset_w[,c(var_of_int,winners)]))

#View(subset[,c(var_of_int,winners)])
'
rownames(t_) <- rownames(signs_table)

temp_ <- merge(t(signs_table), t_, by=0,all.x=TRUE)
rownames(temp_) <- temp_$Row.names
signs_table_ = rowSums(temp_[,2:3],na.rm=TRUE)
signs_table_ = ifelse(signs_table_==0,0,ifelse(signs_table_<0,-1,1))
signs_table = signs_table_ + signs_table

keepers = winners #colnames(sig_table)[sig_table>=(length(folds$train)/2)]
'

#as.data.frame(rbind(sndif_[which(match(colnames(raw),c(var_of_int,winners))>0)],ndif_[which(match(colnames(raw),c(var_of_int,winners))>0)]))
```
```{r}
#newDF_t_ <- newDF[(nrow(training)+1):nrow(combo_),]
#newDF_h_ <- newDF[(nrow(training)+1):nrow(combo_),]

```


```{r}
#min of 1
differences <- as.data.frame(rbind(c(0,lags_[which(match(names,c(var_of_int,winners))>0)]),sndif_[which(match(colnames(raw),c(var_of_int,winners))>0)],ndif_[which(match(colnames(raw),c(var_of_int,winners))>0)]))

#cbind(names[which(match(names,c(var_of_int,winners))>0)],

#lags_[which(match(colnames(raw),c(var_of_int,winners))>0)]
colnames(differences) <- c(var_of_int,winners)

rownames(differences) <- c("lags","season","nonseason")
print(differences)

for(h in c(var_of_int,winners))
{
  hist(subset[,h])
}

lm_raw <- lm(na.omit(newDF_t[,c(var_of_int,winners),drop=FALSE]))
summary(lm_raw)

na.omit(newDF_t[,c(var_of_int,winners),drop=FALSE])

#some seasons
#na.omit(combo_d[,c(var_of_int,winners),drop=FALSE])

```

```{r}

#min of 1

edge <- max(differences["lags",2:ncol(differences),])

ts_ <- stats::lag(x=ts(combo_[,var_of_int,drop=FALSE],frequency=season),k=edge)

d_s <- c(anydate(rownames(raw)[1:edge]),anydate(rownames(raw)[1]) %m+% months(as.double(matrix(time(ts_)))*12))

df_ <- as.data.frame(matrix(NA,nrow=length(d_s)))

rownames(df_) <- anydate(d_s)

newDF <- merge(df_,combo_[,var_of_int,drop=FALSE],by=0,all.x = TRUE)
rownames(newDF) <- newDF$Row.names

newDF <- newDF[,var_of_int,drop=FALSE]

#t_ <- as.data.frame(matrix(NA,nrow=length(d_s)),row.names = d_s)
#merge(t_,raw[,var_of_int,drop=FALSE],by=0,all.x=TRUE)

#newDF <- cbind(df_,combo_[,var_of_int,drop=FALSE])

#nrow(df_)

#nrow(newDF_t)

#newDF_t <- lapply(1:length(names), function(n)
for (n in 1:length(names))
{
  #n=1
  #print(n)
  #temp=dplyr::lag(combo_[,names[n],drop=FALSE],n=abs(lags_[n]),default = NA)
  ts_ <- stats::lag(x=ts(combo_[,names[n],drop=FALSE],frequency=season),k=lags_[n])
  temp <- as.data.frame(matrix(ts_))

  rownames(temp) <- anydate(rownames(combo_)[1]) %m+% months(matrix(time(ts_))*12)
  colnames(temp) <- names[n]

  #rownames(temp)<-rownames(raw)
  #tail(raw[,var_of_int,drop=FALSE])
  #tail(raw[,"ASPUS",drop=FALSE])
  #return(temp)
  temp <- merge(df_,temp,by=0,all.x = TRUE)
  rownames(temp) <- temp$Row.names
  
  temp <- temp[,names[n],drop=FALSE]

  newDF <- cbind(newDF,temp)
  
}

newDF_t_ <- newDF[1:floor(nrow(combo_)*.7),]
#validation <- training-round(nrow(combo_)*.7*.3,0)
newDF_h <- newDF[(nrow(newDF_t_)+1):nrow(combo_),]
```

```{r}
#model construction and holdout analysis

horizon = min(differences["lags",2:ncol(differences),])

f <- as.formula(paste(var_of_int, " ~."))

lm_ <- lm(f, data=na.omit(newDF_t[,c(var_of_int,winners)]))

#summary(lm_)

#checkresiduals(lm_$residuals)

actual <- newDF_h[1:horizon,var_of_int,drop=FALSE]

#straight arima of y
models <- list(
  auto.arima(newDF_t[,var_of_int,drop=FALSE]),
  NA,#auto.arima(lm_$residuals)
  NA,#arfima(lm_$residuals)
  NA,#auto.arima(newDF_t[,var_of_int,drop=FALSE],xreg=lm_$residuals)
  ets(ts(newDF_t[,var_of_int,drop=FALSE],frequency=season)),
  auto.arima(newDF_t[,var_of_int,drop=FALSE],xreg=as.matrix(newDF_t[,winners]))
)

forecasts <- list(
  {
    f_0 <- as.data.frame(forecast(models[[1]],h=horizon))
    rownames(f_0) <- rownames(actual)
    f_0
  },
  if(FALSE)
  {
    #arima of lm residuals
    f_1 <- as.data.frame(forecast(models[[2]],h=horizon))
    f_1a <- f_1 + t(predict(lm_,newdata=newDF_h[1:horizon,winners,drop=FALSE]))
    rownames(f_1a) <- rownames(actual)
    f_1a
  }else
  {
    NA  
  }
  ,
  if(FALSE)
  {
    #arfima of residuals
    f_2 <- as.data.frame(forecast(models[[3]],h=horizon))
    f_2a <- f_2 + t(predict(lm_,newdata=newDF_h[1:horizon,winners,drop=FALSE]))
    rownames(f_2a) <- rownames(actual)
    f_2a
  }else
  {
    NA
  },
  if(FALSE)
  {
    #arima exogenous
    f_3_lm_r <- forecast(lm_, newDF_h[1:horizon,winners,drop=FALSE], h=horizon)
    #test_4 <- arfima(newDF_t[,var_of_int,drop=FALSE],xreg=lm_$residuals,estim=c("mle"))
    f_3a <- as.data.frame(forecast(models[[4]],h=horizon,xreg=f_3_lm_r$mean))
    #lapply(c(2,3,4),function(x){f_3_lm_r[names(f_3_lm_r)[x]]})
    #rownames(f_3a)
    rownames(f_3a) <- rownames(actual)
    f_3a
  }else
    {
      NA
    }
  ,
  {
    f_4 <- as.data.frame(forecast(models[[5]],h=horizon))
    rownames(f_4) <- rownames(actual)
    f_4
  },
  {
    #proper arimax
    f_5 <- as.data.frame(forecast(models[[6]], xreg=as.matrix(newDF_h[1:horizon,winners,drop=FALSE]), h=horizon))
    rownames(f_5) <- rownames(actual)
    f_5
  }
)

errors <- list(
  mean(abs(forecasts[[1]]$`Point Forecast`-t(actual))),
  NA,#mean(abs(forecasts[[2]]$`Point Forecast`-t(actual)))
  NA,#mean(abs(forecasts[[3]]$`Point Forecast`-t(actual))
  NA,#mean(abs(forecasts[[4]]$`Point Forecast`-t(actual)))
  mean(abs(forecasts[[5]]$`Point Forecast`-t(actual))),
  mean(abs(forecasts[[6]]$`Point Forecast`-t(actual)))
)



for (e in 1:length(errors))
{
  print(paste("error forecast:", e, errors[[e]]))
}

which.min(errors)

f_casts = forecasts[which.min(errors)][[1]][,1]

#raw[1,var_of_int,drop=TRUE]

mean_ <- nv_diff_sets(var_of_int,newDF_t,forecasts[which.min(errors)][[1]][,1])
lower_ <- nv_diff_sets(var_of_int,newDF_t,forecasts[which.min(errors)][[1]][,4])
upper_ <- nv_diff_sets(var_of_int,newDF_t,forecasts[which.min(errors)][[1]][,5])

#nrow(actual)

actual_ <- rbind(newDF_t[,var_of_int,drop=FALSE],newDF_h[1:horizon,var_of_int,drop=FALSE])

actual <- nv_diff_sets(var_of_int,actual_,c())

s_=sndif_[which(colnames(raw)==var_of_int)]
d_=ndif_[which(colnames(raw)==var_of_int)]
  
actual_2 <- structure(data.frame(actual, row.names = rownames(actual_)),names=var_of_int)

df <- tail(data.frame(time = anydate(rownames(actual_2)), cbind(actual_2,mean_,lower_,upper_)),horizon*4)

df <- melt(df ,  id.vars = 'time', variable.name = 'series')

ggplot(df, aes(time,value)) + geom_line(aes(colour = variable))
```


```{r}
#actual forecast

fore_data <- newDF[,c(var_of_int,winners)]

lm_a <- lm(f, data=fore_data)

fore_data

#straight arima of y
models_a <- list(
  auto.arima(fore_data[,var_of_int,drop=FALSE]),
  NA,#auto.arima(lm_$residuals)
  NA,#arfima(lm_$residuals)
  NA,#auto.arima(newDF_t[,var_of_int,drop=FALSE],xreg=lm_$residuals)
  ets(ts(fore_data[,var_of_int,drop=FALSE],frequency=season)),
  auto.arima(fore_data[,var_of_int,drop=FALSE],xreg=as.matrix(fore_data[,winners]))
)

forecasts_a <- list(
  {
    f_0 <- as.data.frame(forecast(models_a[[1]],h=horizon))
    f_0
  },
  if(FALSE)
  {
    #arima of lm residuals
    f_1 <- as.data.frame(forecast(models_a[[2]],h=horizon))
    #f_1
    NA
  },
  if(FALSE)
  {
    #arfima of residuals
    f_2 <- as.data.frame(forecast(models_a[[3]],h=horizon))
    #f_2
  }else
  {NA},
  if(FALSE)
  {
    #arima exogenous
    #residuals
    f_3 <- forecast(auto.arima(lm_a$residuals), h=horizon)
    #by selecting models[[4]], it's going to forecast y
    f_3a <- forecast(models_a[[4]],xreg=f_3$mean)
    #f_3a
  }else
    {NA},
  {
    f_4 <- as.data.frame(forecast(models_a[[5]],h=horizon))
    rownames(f_4) <- rownames(actual)
    f_4
  },
  {
    #proper arimax
    f_5 <- as.data.frame(forecast(models_a[[6]], xreg=as.matrix(tail(fore_data[,winners,drop=FALSE],horizon))))
    rownames(f_5) <- rownames(actual)
    f_5
  }
  
)

s_=sndif_[which(colnames(raw)==var_of_int)]
d_=ndif_[which(colnames(raw)==var_of_int)]
data_ <- c(na.omit(c(combo_[,var_of_int],forecasts_a[which.min(errors)][[1]][,1])))

if(s_==0)
{
  inv_d <- diffinv(data_,differences = d_, xi=raw[1:d_,var_of_int])
  inv_d <- diffinv(data_,differences=d_,xi=raw[rownames(newDF_t[1:d_,]),var_of_int])
}else
{
    
  inv_d <- diffinv(diffinv(data_,differences=d_,xi=raw[rownames(newDF_t[1:d_,]),var_of_int]),differences = s_,xi=raw[1:(season+1+d_),var_of_int])
}

mean_ <- nv_diff_sets(var_of_int,(structure(data.frame(c(combo_[,var_of_int]), row.names = rownames(combo_)),names=var_of_int)),forecasts_a[which.min(errors)][[1]][,1])
lower_ <- nv_diff_sets(var_of_int,(structure(data.frame(c(combo_[,var_of_int]), row.names = rownames(combo_)),names=var_of_int)),forecasts_a[which.min(errors)][[1]][,4])
upper_ <- nv_diff_sets(var_of_int,(structure(data.frame(c(combo_[,var_of_int]), row.names = rownames(combo_)),names=var_of_int)),forecasts_a[which.min(errors)][[1]][,5])
      
df_a <- data.frame(time = d_s, mean_,lower_,upper_)

df_a <- melt(tail(df_a,horizon*4) ,  id.vars = 'time', variable.name = 'series')

ggplot(df_a, aes(time,value)) + geom_line(aes(colour = variable))


```


```{r}

```
